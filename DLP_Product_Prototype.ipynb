{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with label criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import requests\n",
    "import pandas as pd\n",
    "import fitz  # PyMuPDF for PDFs\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "# ==============================\n",
    "# Configuration\n",
    "# ==============================\n",
    "# Hugging Face API Configuration:\n",
    "API_URL = \"https://api-inference.huggingface.co/models/facebook/bart-large-mnli\"\n",
    "API_TOKEN = \"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\"\n",
    "HEADERS = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ==============================\n",
    "# Classification Function\n",
    "# ==============================\n",
    "def classify_sensitive_data(text, max_retries=3):\n",
    "    \"\"\"\n",
    "    Classifies text using Hugging Face API and categorizes as \"Sensitive\" or \"Non-Sensitive\".\n",
    "    A document is labeled as sensitive only if at least one of:\n",
    "        \"Medical Diagnosis\", \"Medication\", \"Clinical Notes\", \"Patient Identifiers\"\n",
    "    has a probability > 0.5 AND the \"General Information\" probability is <= 0.5.\n",
    "    Retries up to max_retries if the model is loading.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"inputs\": text,\n",
    "        \"parameters\": {\n",
    "            \"candidate_labels\": [\n",
    "                \"Medical Diagnosis\", \"Medication\", \"Clinical Notes\",\n",
    "                \"Patient Identifiers\", \"General Hospital Information\"\n",
    "            ],\n",
    "            \"multi_label\": True\n",
    "        }\n",
    "    }\n",
    "\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = requests.post(API_URL, headers=HEADERS, json=payload)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error calling Hugging Face API: {e}\")\n",
    "            return None\n",
    "\n",
    "        if response.status_code == 503:\n",
    "            retries += 1\n",
    "            logger.info(\"Model loading... Retrying in 10 seconds.\")\n",
    "            time.sleep(10)\n",
    "        elif response.status_code == 200:\n",
    "            try:\n",
    "                results = response.json()\n",
    "                labels = results.get(\"labels\", [])\n",
    "                scores = results.get(\"scores\", [])\n",
    "                if not labels or not scores:\n",
    "                    logger.error(\"No labels or scores returned from API.\")\n",
    "                    return None\n",
    "\n",
    "                # Create a dictionary mapping each label to its score\n",
    "                label_scores = dict(zip(labels, scores))\n",
    "                general_info_score = label_scores.get(\"General Information\", 0)\n",
    "                sensitive_categories = [\"Medical Diagnosis\", \"Medication\", \"Clinical Notes\", \"Patient Identifiers\"]\n",
    "                # Check if any sensitive category exceeds 0.5 probability\n",
    "                sensitive_found = any(label_scores.get(label, 0) > 0.5 for label in sensitive_categories)\n",
    "                \n",
    "                # Only label as sensitive if a sensitive category > 0.5 exists AND \n",
    "                # \"General Information\" is not too high (> 0.5).\n",
    "                if sensitive_found and general_info_score <= 0.5:\n",
    "                    return \"Sensitive\"\n",
    "                else:\n",
    "                    return \"Non-Sensitive\"\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error parsing API response: {e}\")\n",
    "                return None\n",
    "        else:\n",
    "            logger.error(f\"Error: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "\n",
    "    logger.error(\"Max retries exceeded for classification.\")\n",
    "    return None\n",
    "\n",
    "# ==============================\n",
    "# File Text Extraction\n",
    "# ==============================\n",
    "def extract_text_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Extracts text from PDF, DOCX, or CSV files.\n",
    "    Returns None if file type is unsupported or an error occurs.\n",
    "    \"\"\"\n",
    "    ext = os.path.splitext(file_path)[-1].lower()\n",
    "    try:\n",
    "        if ext == \".pdf\":\n",
    "            doc = fitz.open(file_path)\n",
    "            text = \" \".join(page.get_text(\"text\") for page in doc)\n",
    "            doc.close()\n",
    "            return text\n",
    "        elif ext == \".docx\":\n",
    "            doc = Document(file_path)\n",
    "            return \" \".join(para.text for para in doc.paragraphs)\n",
    "        elif ext == \".csv\":\n",
    "            df = pd.read_csv(file_path, dtype=str, encoding=\"utf-8\")\n",
    "            return \" \".join(df.astype(str).values.flatten())\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting text from {file_path}: {e}\")\n",
    "    return None\n",
    "\n",
    "# ==============================\n",
    "# PDF Processing Functions\n",
    "# ==============================\n",
    "def add_watermark_to_pdf(pdf_path, watermark_text=\"SENSITIVE DATA - observe company policy.\"):\n",
    "    \"\"\"\n",
    "    Adds a watermark to a PDF file if not already present on each page.\n",
    "    The watermark is applied by saving to a temporary file (with a full save) and then\n",
    "    replacing the original file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Could not open PDF {pdf_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    if doc.is_encrypted:\n",
    "        try:\n",
    "            doc.authenticate(\"\")  # Attempt to unlock with an empty password\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Skipping encrypted PDF {pdf_path}: {e}\")\n",
    "            doc.close()\n",
    "            return\n",
    "\n",
    "    modified = False\n",
    "    for page in doc:\n",
    "        # Check if the watermark text is already present on this page.\n",
    "        # If not found, insert the watermark.\n",
    "        if not page.search_for(watermark_text):\n",
    "            page.insert_text(\n",
    "                (50, 500),\n",
    "                watermark_text,\n",
    "                fontsize=15,\n",
    "                color=(1, 0, 0),\n",
    "                rotate=90\n",
    "            )\n",
    "            modified = True\n",
    "\n",
    "    if not modified:\n",
    "        logger.info(f\"Watermark already present in PDF: {pdf_path}\")\n",
    "        doc.close()\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Save to a temporary file using a full (non-incremental) save.\n",
    "        temp_pdf = pdf_path.replace(\".pdf\", \"_watermarked.pdf\")\n",
    "        doc.save(temp_pdf, incremental=False)\n",
    "        doc.close()\n",
    "        # Replace the original file with the updated file.\n",
    "        os.replace(temp_pdf, pdf_path)\n",
    "        logger.info(f\"Watermark added to PDF: {pdf_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing PDF {pdf_path}: {e}\")\n",
    "\n",
    "\n",
    "def modify_pdf_metadata(pdf_path):\n",
    "    \"\"\"\n",
    "    Modifies metadata of a PDF file to mark it as 'Sensitive'.\n",
    "    Saves to a temporary file and then replaces the original file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        metadata = doc.metadata or {}\n",
    "        metadata[\"subject\"] = \"Sensitive Document\"\n",
    "        metadata[\"keywords\"] = \"Sensitive, Confidential, Restricted\"\n",
    "        metadata[\"producer\"] = \"DLP System\"\n",
    "        doc.set_metadata(metadata)\n",
    "        \n",
    "        # Save to a temporary file instead of modifying the original directly.\n",
    "        temp_pdf = pdf_path.replace(\".pdf\", \"_metadata.pdf\")\n",
    "        doc.save(temp_pdf)  # Full save to temp file\n",
    "        doc.close()\n",
    "        \n",
    "        # Replace the original PDF with the updated one.\n",
    "        os.replace(temp_pdf, pdf_path)\n",
    "        logger.info(f\"Metadata updated in PDF: {pdf_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error modifying PDF metadata for {pdf_path}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# DOCX Processing Functions\n",
    "# ==============================\n",
    "from docx.shared import RGBColor\n",
    "from docx.shared import RGBColor, Pt\n",
    "\n",
    "def add_watermark_to_docx(docx_path):\n",
    "    \"\"\"\n",
    "    Adds a red, bold watermark header with font size 14 to a DOCX file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = Document(docx_path)\n",
    "        header = doc.sections[0].header\n",
    "        \n",
    "        # Use the first paragraph in the header or add a new one.\n",
    "        if header.paragraphs:\n",
    "            header_paragraph = header.paragraphs[0]\n",
    "            # Clear any existing text in the paragraph.\n",
    "            header_paragraph.clear()\n",
    "        else:\n",
    "            header_paragraph = header.add_paragraph()\n",
    "        \n",
    "        # Add a new run with the watermark text and set its formatting.\n",
    "        run = header_paragraph.add_run(\"SENSITIVE DATA - observe company policy.\")\n",
    "        run.font.color.rgb = RGBColor(255, 0, 0)  # Set text color to red.\n",
    "        run.font.bold = True                      # Make the text bold.\n",
    "        run.font.size = Pt(14)                    # Set font size to 14 points.\n",
    "        \n",
    "        doc.save(docx_path)\n",
    "        logger.info(f\"Watermark added to DOCX: {docx_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing DOCX {docx_path}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def modify_docx_metadata(docx_path):\n",
    "    \"\"\"\n",
    "    Modifies metadata of a DOCX file to mark it as 'Sensitive'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = Document(docx_path)\n",
    "        core_props = doc.core_properties\n",
    "        core_props.subject = \"Sensitive Document\"\n",
    "        core_props.keywords = \"Sensitive, Confidential\"\n",
    "        core_props.author = \"DLP System\"\n",
    "        doc.save(docx_path)\n",
    "        logger.info(f\"Metadata updated in DOCX: {docx_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error modifying DOCX metadata for {docx_path}: {e}\")\n",
    "\n",
    "# ==============================\n",
    "# CSV Processing Function\n",
    "# ==============================\n",
    "def process_csv_file(csv_path):\n",
    "    \"\"\"\n",
    "    Adds a 'Sensitive_Flag' column to a CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path, dtype=str, encoding=\"utf-8\")\n",
    "        df[\"Sensitive_Flag\"] = \"True\"\n",
    "        df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "        logger.info(f\"Sensitivity flag added to CSV: {csv_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing CSV {csv_path}: {e}\")\n",
    "\n",
    "# ==============================\n",
    "# Main Processing Function\n",
    "# ==============================\n",
    "def scan_folder_for_sensitive_data(folder_path):\n",
    "    \"\"\"\n",
    "    Scans a folder for PDF, DOCX, and CSV files, classifies them for sensitive data,\n",
    "    and applies watermarking and metadata modifications accordingly.\n",
    "    \"\"\"\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            text = extract_text_from_file(file_path)\n",
    "            if not text:\n",
    "                logger.debug(f\"No text extracted                                                                                                                                                                                                            from {file_path}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            classification = classify_sensitive_data(text)\n",
    "            if classification is None:\n",
    "                logger.error(f\"Could not classify {file_path}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            logger.info(f\"File: {file_path} -> Classification: {classification}\")\n",
    "\n",
    "            if classification == \"Sensitive\":\n",
    "                ext = os.path.splitext(file)[-1].lower()\n",
    "                if ext == \".pdf\":\n",
    "                    add_watermark_to_pdf(file_path)\n",
    "                    modify_pdf_metadata(file_path)\n",
    "                elif ext == \".docx\":\n",
    "                    add_watermark_to_docx(file_path)\n",
    "                    modify_docx_metadata(file_path)\n",
    "                elif ext == \".csv\":\n",
    "                    process_csv_file(file_path)\n",
    "                else:\n",
    "                    logger.warning(f\"Unsupported file type for {file_path}\")\n",
    "\n",
    "# ==============================\n",
    "# Command-line Interface\n",
    "# ==============================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_to_scan = \"test_documents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-09 10:08:13,710 [INFO] File: test_documents\\test_file_1.csv -> Classification: Sensitive\n",
      "2025-02-09 10:08:13,714 [INFO] Sensitivity flag added to CSV: test_documents\\test_file_1.csv\n",
      "2025-02-09 10:08:13,929 [INFO] File: test_documents\\test_file_1.docx -> Classification: Sensitive\n",
      "2025-02-09 10:08:13,953 [INFO] Watermark added to DOCX: test_documents\\test_file_1.docx\n",
      "2025-02-09 10:08:13,982 [INFO] Metadata updated in DOCX: test_documents\\test_file_1.docx\n",
      "2025-02-09 10:08:14,930 [INFO] File: test_documents\\test_file_1.pdf -> Classification: Sensitive\n",
      "2025-02-09 10:08:14,939 [INFO] Watermark added to PDF: test_documents\\test_file_1.pdf\n",
      "2025-02-09 10:08:14,945 [INFO] Metadata updated in PDF: test_documents\\test_file_1.pdf\n",
      "2025-02-09 10:08:23,807 [INFO] File: test_documents\\test_file_2.csv -> Classification: Sensitive\n",
      "2025-02-09 10:08:23,811 [INFO] Sensitivity flag added to CSV: test_documents\\test_file_2.csv\n",
      "2025-02-09 10:08:24,350 [INFO] File: test_documents\\test_file_2.docx -> Classification: Sensitive\n",
      "2025-02-09 10:08:24,375 [INFO] Watermark added to DOCX: test_documents\\test_file_2.docx\n",
      "2025-02-09 10:08:24,415 [INFO] Metadata updated in DOCX: test_documents\\test_file_2.docx\n",
      "2025-02-09 10:08:34,999 [INFO] File: test_documents\\test_file_2.pdf -> Classification: Sensitive\n",
      "2025-02-09 10:08:35,007 [INFO] Watermark added to PDF: test_documents\\test_file_2.pdf\n",
      "2025-02-09 10:08:35,014 [INFO] Metadata updated in PDF: test_documents\\test_file_2.pdf\n",
      "2025-02-09 10:08:43,276 [INFO] File: test_documents\\test_file_3.csv -> Classification: Sensitive\n",
      "2025-02-09 10:08:43,280 [INFO] Sensitivity flag added to CSV: test_documents\\test_file_3.csv\n",
      "2025-02-09 10:08:43,825 [INFO] File: test_documents\\test_file_3.docx -> Classification: Sensitive\n",
      "2025-02-09 10:08:43,856 [INFO] Watermark added to DOCX: test_documents\\test_file_3.docx\n",
      "2025-02-09 10:08:43,881 [INFO] Metadata updated in DOCX: test_documents\\test_file_3.docx\n",
      "2025-02-09 10:08:49,326 [INFO] File: test_documents\\test_file_3.pdf -> Classification: Sensitive\n",
      "2025-02-09 10:08:49,334 [INFO] Watermark added to PDF: test_documents\\test_file_3.pdf\n",
      "2025-02-09 10:08:49,340 [INFO] Metadata updated in PDF: test_documents\\test_file_3.pdf\n",
      "2025-02-09 10:08:50,572 [INFO] File: test_documents\\test_file_4.csv -> Classification: Sensitive\n",
      "2025-02-09 10:08:50,576 [INFO] Sensitivity flag added to CSV: test_documents\\test_file_4.csv\n",
      "2025-02-09 10:08:50,786 [INFO] File: test_documents\\test_file_4.docx -> Classification: Sensitive\n",
      "2025-02-09 10:08:50,812 [INFO] Watermark added to DOCX: test_documents\\test_file_4.docx\n",
      "2025-02-09 10:08:50,869 [INFO] Metadata updated in DOCX: test_documents\\test_file_4.docx\n",
      "2025-02-09 10:08:52,004 [INFO] File: test_documents\\test_file_4.pdf -> Classification: Sensitive\n",
      "2025-02-09 10:08:52,012 [INFO] Watermark added to PDF: test_documents\\test_file_4.pdf\n",
      "2025-02-09 10:08:52,018 [INFO] Metadata updated in PDF: test_documents\\test_file_4.pdf\n",
      "2025-02-09 10:08:52,239 [INFO] File: test_documents\\test_file_5.csv -> Classification: Sensitive\n",
      "2025-02-09 10:08:52,242 [INFO] Sensitivity flag added to CSV: test_documents\\test_file_5.csv\n",
      "2025-02-09 10:08:52,468 [INFO] File: test_documents\\test_file_5.docx -> Classification: Sensitive\n",
      "2025-02-09 10:08:52,497 [INFO] Watermark added to DOCX: test_documents\\test_file_5.docx\n",
      "2025-02-09 10:08:52,531 [INFO] Metadata updated in DOCX: test_documents\\test_file_5.docx\n",
      "2025-02-09 10:08:52,746 [INFO] File: test_documents\\test_file_5.pdf -> Classification: Sensitive\n",
      "2025-02-09 10:08:52,754 [INFO] Watermark added to PDF: test_documents\\test_file_5.pdf\n",
      "2025-02-09 10:08:52,760 [INFO] Metadata updated in PDF: test_documents\\test_file_5.pdf\n",
      "2025-02-09 10:08:53,831 [INFO] File: test_documents\\subfolder_10\\test_file_3.csv -> Classification: Non-Sensitive\n",
      "2025-02-09 10:08:54,067 [INFO] File: test_documents\\subfolder_10\\test_file_3.docx -> Classification: Non-Sensitive\n",
      "2025-02-09 10:08:55,119 [INFO] File: test_documents\\subfolder_10\\test_file_3.pdf -> Classification: Non-Sensitive\n",
      "2025-02-09 10:08:56,222 [INFO] File: test_documents\\subfolder_5\\subfolder_2\\subfolder_5\\test_file_5.csv -> Classification: Sensitive\n",
      "2025-02-09 10:08:56,227 [INFO] Sensitivity flag added to CSV: test_documents\\subfolder_5\\subfolder_2\\subfolder_5\\test_file_5.csv\n",
      "2025-02-09 10:08:56,461 [INFO] File: test_documents\\subfolder_5\\subfolder_2\\subfolder_5\\test_file_5.docx -> Classification: Sensitive\n",
      "2025-02-09 10:08:56,514 [INFO] Watermark added to DOCX: test_documents\\subfolder_5\\subfolder_2\\subfolder_5\\test_file_5.docx\n",
      "2025-02-09 10:08:56,542 [INFO] Metadata updated in DOCX: test_documents\\subfolder_5\\subfolder_2\\subfolder_5\\test_file_5.docx\n",
      "2025-02-09 10:08:57,619 [INFO] File: test_documents\\subfolder_5\\subfolder_2\\subfolder_5\\test_file_5.pdf -> Classification: Non-Sensitive\n",
      "2025-02-09 10:08:57,866 [INFO] File: test_documents\\subfolder_5\\subfolder_8\\subfolder_7\\test_file_4.csv -> Classification: Sensitive\n",
      "2025-02-09 10:08:57,871 [INFO] Sensitivity flag added to CSV: test_documents\\subfolder_5\\subfolder_8\\subfolder_7\\test_file_4.csv\n",
      "2025-02-09 10:08:58,096 [INFO] File: test_documents\\subfolder_5\\subfolder_8\\subfolder_7\\test_file_4.docx -> Classification: Sensitive\n",
      "2025-02-09 10:08:58,155 [INFO] Watermark added to DOCX: test_documents\\subfolder_5\\subfolder_8\\subfolder_7\\test_file_4.docx\n",
      "2025-02-09 10:08:58,211 [INFO] Metadata updated in DOCX: test_documents\\subfolder_5\\subfolder_8\\subfolder_7\\test_file_4.docx\n",
      "2025-02-09 10:08:58,423 [INFO] File: test_documents\\subfolder_5\\subfolder_8\\subfolder_7\\test_file_4.pdf -> Classification: Sensitive\n",
      "2025-02-09 10:08:58,433 [INFO] Watermark added to PDF: test_documents\\subfolder_5\\subfolder_8\\subfolder_7\\test_file_4.pdf\n",
      "2025-02-09 10:08:58,443 [INFO] Metadata updated in PDF: test_documents\\subfolder_5\\subfolder_8\\subfolder_7\\test_file_4.pdf\n",
      "2025-02-09 10:08:59,617 [INFO] File: test_documents\\subfolder_7\\subfolder_9\\test_file_2.csv -> Classification: Sensitive\n",
      "2025-02-09 10:08:59,624 [INFO] Sensitivity flag added to CSV: test_documents\\subfolder_7\\subfolder_9\\test_file_2.csv\n",
      "2025-02-09 10:08:59,904 [INFO] File: test_documents\\subfolder_7\\subfolder_9\\test_file_2.docx -> Classification: Sensitive\n",
      "2025-02-09 10:08:59,986 [INFO] Watermark added to DOCX: test_documents\\subfolder_7\\subfolder_9\\test_file_2.docx\n",
      "2025-02-09 10:09:00,027 [INFO] Metadata updated in DOCX: test_documents\\subfolder_7\\subfolder_9\\test_file_2.docx\n",
      "2025-02-09 10:09:01,163 [INFO] File: test_documents\\subfolder_7\\subfolder_9\\test_file_2.pdf -> Classification: Sensitive\n",
      "2025-02-09 10:09:01,176 [INFO] Watermark added to PDF: test_documents\\subfolder_7\\subfolder_9\\test_file_2.pdf\n",
      "2025-02-09 10:09:01,186 [INFO] Metadata updated in PDF: test_documents\\subfolder_7\\subfolder_9\\test_file_2.pdf\n",
      "2025-02-09 10:09:01,407 [INFO] File: test_documents\\subfolder_9\\test_file_1.csv -> Classification: Non-Sensitive\n",
      "2025-02-09 10:09:01,668 [INFO] File: test_documents\\subfolder_9\\test_file_1.docx -> Classification: Non-Sensitive\n",
      "2025-02-09 10:09:01,908 [INFO] File: test_documents\\subfolder_9\\test_file_1.pdf -> Classification: Non-Sensitive\n"
     ]
    }
   ],
   "source": [
    "scan_folder_for_sensitive_data(folder_to_scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without label criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import requests\n",
    "import pandas as pd\n",
    "import fitz  # PyMuPDF for PDFs\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "# ==============================\n",
    "# Configuration\n",
    "# ==============================\n",
    "# Hugging Face API Configuration:\n",
    "API_URL = \"https://api-inference.huggingface.co/models/facebook/bart-large-mnli\"\n",
    "API_TOKEN = \"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\"\n",
    "HEADERS = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ==============================\n",
    "# Classification Function\n",
    "# ==============================\n",
    "def classify_sensitive_data(text, max_retries=3):\n",
    "    \"\"\"\n",
    "    Classifies text using Hugging Face API and categorizes as \"Sensitive\" or \"Non-Sensitive\".\n",
    "    Retries up to max_retries if the model is loading.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"inputs\": text,\n",
    "        \"parameters\": {\n",
    "            \"candidate_labels\": [\n",
    "                \"Medical Diagnosis\", \"Medication\", \"Clinical Notes\",\n",
    "                \"Patient Identifiers\", \"General Information\"\n",
    "            ],\n",
    "            \"multi_label\": True\n",
    "        }\n",
    "    }\n",
    "\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = requests.post(API_URL, headers=HEADERS, json=payload)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error calling Hugging Face API: {e}\")\n",
    "            return None\n",
    "\n",
    "        if response.status_code == 503:\n",
    "            retries += 1\n",
    "            logger.info(\"Model loading... Retrying in 10 seconds.\")\n",
    "            time.sleep(10)\n",
    "        elif response.status_code == 200:\n",
    "            try:\n",
    "                results = response.json()\n",
    "                labels = results.get(\"labels\", [])\n",
    "                sensitive_categories = {\"Medical Diagnosis\", \"Medication\", \"Clinical Notes\", \"Patient Identifiers\"}\n",
    "                is_sensitive = any(label in sensitive_categories for label in labels)\n",
    "                return \"Sensitive\" if is_sensitive else \"Non-Sensitive\"\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error parsing API response: {e}\")\n",
    "                return None\n",
    "        else:\n",
    "            logger.error(f\"Error: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "\n",
    "    logger.error(\"Max retries exceeded for classification.\")\n",
    "    return None\n",
    "\n",
    "# ==============================\n",
    "# File Text Extraction\n",
    "# ==============================\n",
    "def extract_text_from_file(file_path):\n",
    "    \"\"\"\n",
    "    Extracts text from PDF, DOCX, or CSV files.\n",
    "    Returns None if file type is unsupported or an error occurs.\n",
    "    \"\"\"\n",
    "    ext = os.path.splitext(file_path)[-1].lower()\n",
    "    try:\n",
    "        if ext == \".pdf\":\n",
    "            doc = fitz.open(file_path)\n",
    "            text = \" \".join(page.get_text(\"text\") for page in doc)\n",
    "            doc.close()\n",
    "            return text\n",
    "        elif ext == \".docx\":\n",
    "            doc = Document(file_path)\n",
    "            return \" \".join(para.text for para in doc.paragraphs)\n",
    "        elif ext == \".csv\":\n",
    "            df = pd.read_csv(file_path, dtype=str, encoding=\"utf-8\")\n",
    "            return \" \".join(df.astype(str).values.flatten())\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting text from {file_path}: {e}\")\n",
    "    return None\n",
    "\n",
    "# ==============================\n",
    "# PDF Processing Functions\n",
    "# ==============================\n",
    "def add_watermark_to_pdf(pdf_path, watermark_text=\"SENSITIVE DATA - observe company policy.\"):\n",
    "    \"\"\"\n",
    "    Adds a watermark to a PDF file if not already present on each page.\n",
    "    The watermark is applied by saving to a temporary file (with a full save) and then\n",
    "    replacing the original file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Could not open PDF {pdf_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    if doc.is_encrypted:\n",
    "        try:\n",
    "            doc.authenticate(\"\")  # Attempt to unlock with an empty password\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Skipping encrypted PDF {pdf_path}: {e}\")\n",
    "            doc.close()\n",
    "            return\n",
    "\n",
    "    modified = False\n",
    "    for page in doc:\n",
    "        # Check if the watermark text is already present on this page.\n",
    "        # If not found, insert the watermark.\n",
    "        if not page.search_for(watermark_text):\n",
    "            page.insert_text(\n",
    "                (50, 500),\n",
    "                watermark_text,\n",
    "                fontsize=15,\n",
    "                color=(1, 0, 0),\n",
    "                rotate=90\n",
    "            )\n",
    "            modified = True\n",
    "\n",
    "    if not modified:\n",
    "        logger.info(f\"Watermark already present in PDF: {pdf_path}\")\n",
    "        doc.close()\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Save to a temporary file using a full (non-incremental) save.\n",
    "        temp_pdf = pdf_path.replace(\".pdf\", \"_watermarked.pdf\")\n",
    "        doc.save(temp_pdf, incremental=False)\n",
    "        doc.close()\n",
    "        # Replace the original file with the updated file.\n",
    "        os.replace(temp_pdf, pdf_path)\n",
    "        logger.info(f\"Watermark added to PDF: {pdf_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing PDF {pdf_path}: {e}\")\n",
    "\n",
    "\n",
    "def modify_pdf_metadata(pdf_path):\n",
    "    \"\"\"\n",
    "    Modifies metadata of a PDF file to mark it as 'Sensitive'.\n",
    "    Saves to a temporary file and then replaces the original file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        metadata = doc.metadata or {}\n",
    "        metadata[\"subject\"] = \"Sensitive Document\"\n",
    "        metadata[\"keywords\"] = \"Sensitive, Confidential, Restricted\"\n",
    "        metadata[\"producer\"] = \"DLP System\"\n",
    "        doc.set_metadata(metadata)\n",
    "        \n",
    "        # Save to a temporary file instead of modifying the original directly.\n",
    "        temp_pdf = pdf_path.replace(\".pdf\", \"_metadata.pdf\")\n",
    "        doc.save(temp_pdf)  # Full save to temp file\n",
    "        doc.close()\n",
    "        \n",
    "        # Replace the original PDF with the updated one.\n",
    "        os.replace(temp_pdf, pdf_path)\n",
    "        logger.info(f\"Metadata updated in PDF: {pdf_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error modifying PDF metadata for {pdf_path}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# DOCX Processing Functions\n",
    "# ==============================\n",
    "from docx.shared import RGBColor\n",
    "from docx.shared import RGBColor, Pt\n",
    "\n",
    "def add_watermark_to_docx(docx_path):\n",
    "    \"\"\"\n",
    "    Adds a red, bold watermark header with font size 14 to a DOCX file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = Document(docx_path)\n",
    "        header = doc.sections[0].header\n",
    "        \n",
    "        # Use the first paragraph in the header or add a new one.\n",
    "        if header.paragraphs:\n",
    "            header_paragraph = header.paragraphs[0]\n",
    "            # Clear any existing text in the paragraph.\n",
    "            header_paragraph.clear()\n",
    "        else:\n",
    "            header_paragraph = header.add_paragraph()\n",
    "        \n",
    "        # Add a new run with the watermark text and set its formatting.\n",
    "        run = header_paragraph.add_run(\"SENSITIVE DATA - observe company policy.\")\n",
    "        run.font.color.rgb = RGBColor(255, 0, 0)  # Set text color to red.\n",
    "        run.font.bold = True                      # Make the text bold.\n",
    "        run.font.size = Pt(14)                    # Set font size to 14 points.\n",
    "        \n",
    "        doc.save(docx_path)\n",
    "        logger.info(f\"Watermark added to DOCX: {docx_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing DOCX {docx_path}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def modify_docx_metadata(docx_path):\n",
    "    \"\"\"\n",
    "    Modifies metadata of a DOCX file to mark it as 'Sensitive'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = Document(docx_path)\n",
    "        core_props = doc.core_properties\n",
    "        core_props.subject = \"Sensitive Document\"\n",
    "        core_props.keywords = \"Sensitive, Confidential\"\n",
    "        core_props.author = \"DLP System\"\n",
    "        doc.save(docx_path)\n",
    "        logger.info(f\"Metadata updated in DOCX: {docx_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error modifying DOCX metadata for {docx_path}: {e}\")\n",
    "\n",
    "# ==============================\n",
    "# CSV Processing Function\n",
    "# ==============================\n",
    "def process_csv_file(csv_path):\n",
    "    \"\"\"\n",
    "    Adds a 'Sensitive_Flag' column to a CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path, dtype=str, encoding=\"utf-8\")\n",
    "        df[\"Sensitive_Flag\"] = \"True\"\n",
    "        df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "        logger.info(f\"Sensitivity flag added to CSV: {csv_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing CSV {csv_path}: {e}\")\n",
    "\n",
    "# ==============================\n",
    "# Main Processing Function\n",
    "# ==============================\n",
    "def scan_folder_for_sensitive_data(folder_path):\n",
    "    \"\"\"\n",
    "    Scans a folder for PDF, DOCX, and CSV files, classifies them for sensitive data,\n",
    "    and applies watermarking and metadata modifications accordingly.\n",
    "    \"\"\"\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            text = extract_text_from_file(file_path)\n",
    "            if not text:\n",
    "                logger.debug(f\"No text extracted                                                                                                                                                                                                            from {file_path}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            classification = classify_sensitive_data(text)\n",
    "            if classification is None:\n",
    "                logger.error(f\"Could not classify {file_path}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            logger.info(f\"File: {file_path} -> Classification: {classification}\")\n",
    "\n",
    "            if classification == \"Sensitive\":\n",
    "                ext = os.path.splitext(file)[-1].lower()\n",
    "                if ext == \".pdf\":\n",
    "                    add_watermark_to_pdf(file_path)\n",
    "                    modify_pdf_metadata(file_path)\n",
    "                elif ext == \".docx\":\n",
    "                    add_watermark_to_docx(file_path)\n",
    "                    modify_docx_metadata(file_path)\n",
    "                elif ext == \".csv\":\n",
    "                    process_csv_file(file_path)\n",
    "                else:\n",
    "                    logger.warning(f\"Unsupported file type for {file_path}\")\n",
    "\n",
    "# ==============================\n",
    "# Command-line Interface\n",
    "# ==============================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-08 19:49:21,671 [INFO] File: test_documents\\test_file_1.csv -> Classification: Sensitive\n",
      "2025-02-08 19:49:21,677 [INFO] Sensitivity flag added to CSV: test_documents\\test_file_1.csv\n",
      "2025-02-08 19:49:21,901 [INFO] File: test_documents\\test_file_1.docx -> Classification: Sensitive\n",
      "2025-02-08 19:49:21,965 [INFO] Watermark added to DOCX: test_documents\\test_file_1.docx\n",
      "2025-02-08 19:49:22,022 [INFO] Metadata updated in DOCX: test_documents\\test_file_1.docx\n",
      "2025-02-08 19:49:22,238 [INFO] File: test_documents\\test_file_1.pdf -> Classification: Sensitive\n",
      "2025-02-08 19:49:22,245 [INFO] Watermark already present in PDF: test_documents\\test_file_1.pdf\n",
      "2025-02-08 19:49:22,254 [INFO] Metadata updated in PDF: test_documents\\test_file_1.pdf\n",
      "2025-02-08 19:49:22,462 [INFO] File: test_documents\\test_file_2.csv -> Classification: Sensitive\n",
      "2025-02-08 19:49:22,468 [INFO] Sensitivity flag added to CSV: test_documents\\test_file_2.csv\n",
      "2025-02-08 19:49:22,675 [INFO] File: test_documents\\test_file_2.docx -> Classification: Sensitive\n",
      "2025-02-08 19:49:22,717 [INFO] Watermark added to DOCX: test_documents\\test_file_2.docx\n",
      "2025-02-08 19:49:22,780 [INFO] Metadata updated in DOCX: test_documents\\test_file_2.docx\n",
      "2025-02-08 19:49:22,981 [INFO] File: test_documents\\test_file_2.pdf -> Classification: Sensitive\n",
      "2025-02-08 19:49:22,987 [INFO] Watermark already present in PDF: test_documents\\test_file_2.pdf\n",
      "2025-02-08 19:49:22,995 [INFO] Metadata updated in PDF: test_documents\\test_file_2.pdf\n",
      "2025-02-08 19:49:23,204 [INFO] File: test_documents\\test_file_3.csv -> Classification: Sensitive\n",
      "2025-02-08 19:49:23,211 [INFO] Sensitivity flag added to CSV: test_documents\\test_file_3.csv\n",
      "2025-02-08 19:49:23,436 [INFO] File: test_documents\\test_file_3.docx -> Classification: Sensitive\n",
      "2025-02-08 19:49:23,481 [INFO] Watermark added to DOCX: test_documents\\test_file_3.docx\n",
      "2025-02-08 19:49:23,516 [INFO] Metadata updated in DOCX: test_documents\\test_file_3.docx\n",
      "2025-02-08 19:49:23,723 [INFO] File: test_documents\\test_file_3.pdf -> Classification: Sensitive\n",
      "2025-02-08 19:49:23,727 [INFO] Watermark already present in PDF: test_documents\\test_file_3.pdf\n",
      "2025-02-08 19:49:23,735 [INFO] Metadata updated in PDF: test_documents\\test_file_3.pdf\n",
      "2025-02-08 19:49:23,946 [INFO] File: test_documents\\test_file_4.csv -> Classification: Sensitive\n",
      "2025-02-08 19:49:23,949 [INFO] Sensitivity flag added to CSV: test_documents\\test_file_4.csv\n",
      "2025-02-08 19:49:24,159 [INFO] File: test_documents\\test_file_4.docx -> Classification: Sensitive\n",
      "2025-02-08 19:49:24,186 [INFO] Watermark added to DOCX: test_documents\\test_file_4.docx\n",
      "2025-02-08 19:49:24,240 [INFO] Metadata updated in DOCX: test_documents\\test_file_4.docx\n",
      "2025-02-08 19:49:24,442 [INFO] File: test_documents\\test_file_4.pdf -> Classification: Sensitive\n",
      "2025-02-08 19:49:24,445 [INFO] Watermark already present in PDF: test_documents\\test_file_4.pdf\n",
      "2025-02-08 19:49:24,452 [INFO] Metadata updated in PDF: test_documents\\test_file_4.pdf\n",
      "2025-02-08 19:49:24,646 [INFO] File: test_documents\\test_file_5.csv -> Classification: Sensitive\n",
      "2025-02-08 19:49:24,651 [INFO] Sensitivity flag added to CSV: test_documents\\test_file_5.csv\n",
      "2025-02-08 19:49:24,863 [INFO] File: test_documents\\test_file_5.docx -> Classification: Sensitive\n",
      "2025-02-08 19:49:24,897 [INFO] Watermark added to DOCX: test_documents\\test_file_5.docx\n",
      "2025-02-08 19:49:24,925 [INFO] Metadata updated in DOCX: test_documents\\test_file_5.docx\n",
      "2025-02-08 19:49:25,133 [INFO] File: test_documents\\test_file_5.pdf -> Classification: Sensitive\n",
      "2025-02-08 19:49:25,137 [INFO] Watermark already present in PDF: test_documents\\test_file_5.pdf\n",
      "2025-02-08 19:49:25,143 [INFO] Metadata updated in PDF: test_documents\\test_file_5.pdf\n"
     ]
    }
   ],
   "source": [
    "scan_folder_for_sensitive_data(folder_to_scan)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
