{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import fitz  # PyMuPDF for PDFs\n",
    "import docx  # For .docx extraction\n",
    "\n",
    "# Hugging Face API Settings\n",
    "HF_API_URL = \"https://api-inference.huggingface.co/models/facebook/bart-large-mnli\"\n",
    "HEADERS = {\"Authorization\": \"Bearer hf_your_actual_token\"}  # Replace with your HF token\n",
    "\n",
    "# DLP Dictionary (Example)\n",
    "icu_data_dict = {\n",
    "    \"Patient_Identifiers\": {\n",
    "        \"Fields\": {\n",
    "            \"Complete_Name\": {\n",
    "                \"Field_Identifier\": [r\"\\b(?:[Nn]ome)\\b\", r\"\\b[Nn]ome\\s{0,3}(?:d[oa])?\\s{0,3}[Pp]aciente\\b\"],\n",
    "                \"Content_Identifier\": r\"\\b[A-ZÀ-Ÿ][a-zà-ÿ]+\\s{0,3}-?(?:da|de|do|dos|das|di|von)?\\s{0,3}[A-ZÀ-Ÿ][a-zà-ÿ]+\\b\",\n",
    "                \"DLP_Strategy\": \"Detects full names.\"\n",
    "            },\n",
    "            \"Diagnósticos\": {\n",
    "                \"Field_Identifier\": [r\"\\b(?:Diagnóstico|Diagnósticos|Doença)\\b\"],\n",
    "                \"Content_Identifier\": None,  # Requires HF API classification\n",
    "                \"DLP_Strategy\": \"Uses NLP to classify medical diagnosis.\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Hugging Face API Call for Classification\n",
    "def classify_sensitive_data(text):\n",
    "    \"\"\"\n",
    "    Uses HF API to classify text into categories & determines if it's sensitive.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"inputs\": text,\n",
    "        \"parameters\": {\n",
    "            \"candidate_labels\": [\n",
    "                \"Medical Diagnosis\", \"Medication\", \"Clinical Notes\",\n",
    "                \"Patient Identifiers\", \"General Information\"\n",
    "            ],\n",
    "            \"multi_label\": True\n",
    "        }\n",
    "    }\n",
    "\n",
    "    while True:\n",
    "        response = requests.post(HF_API_URL, headers=HEADERS, json=payload)\n",
    "        \n",
    "        if response.status_code == 503:\n",
    "            print(\"Model is still loading... Retrying in 10 seconds.\")\n",
    "            time.sleep(10)\n",
    "        elif response.status_code == 200:\n",
    "            results = response.json()\n",
    "            labels = results[\"labels\"]\n",
    "            scores = results[\"scores\"]\n",
    "\n",
    "            # Print probability scores\n",
    "            print(\"\\n🔹 **Classification Probabilities:**\")\n",
    "            for label, score in zip(labels, scores):\n",
    "                print(f\"{label}: {score:.2%}\")\n",
    "\n",
    "            # Return the top classification label\n",
    "            return labels[0] if scores[0] > 0.5 else \"Non-Sensitive\"\n",
    "\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}, {response.text}\")\n",
    "            return None\n",
    "\n",
    "# Function to Extract Text from Different File Types\n",
    "def extract_text_from_file(file_path):\n",
    "    \"\"\"Extracts text from PDFs, DOCX, and CSV files.\"\"\"\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "\n",
    "    if ext == \".pdf\":\n",
    "        text = \"\"\n",
    "        with fitz.open(file_path) as doc:\n",
    "            for page in doc:\n",
    "                text += page.get_text()\n",
    "        return text\n",
    "\n",
    "    elif ext == \".docx\":\n",
    "        doc = docx.Document(file_path)\n",
    "        return \" \".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "    elif ext == \".csv\":\n",
    "        df = pd.read_csv(file_path, dtype=str, encoding=\"utf-8\", errors=\"ignore\")\n",
    "        return \" \".join(df.astype(str).values.flatten())\n",
    "\n",
    "    return None  # Unsupported file type\n",
    "\n",
    "# Function to Scan Folder for Sensitive Data\n",
    "def scan_folder_for_sensitive_data(folder_path):\n",
    "    \"\"\"Traverses folders, extracts text, matches DLP patterns, and classifies sensitive data.\"\"\"\n",
    "    alerts = []\n",
    "\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_text = extract_text_from_file(file_path)\n",
    "\n",
    "            if not file_text:\n",
    "                continue  # Skip if no text extracted\n",
    "\n",
    "            for category, data in icu_data_dict.items():\n",
    "                for field_name, field_info in data[\"Fields\"].items():\n",
    "                    # Search for field identifiers\n",
    "                    for field_pattern in field_info[\"Field_Identifier\"]:\n",
    "                        if re.search(field_pattern, file_text, re.IGNORECASE):\n",
    "                            # If complex field, use HF API to classify\n",
    "                            if field_info[\"Content_Identifier\"] is None:\n",
    "                                classification = classify_sensitive_data(file_text[:500])  # First 500 chars\n",
    "                                alerts.append((file_path, file, field_name, classification))\n",
    "                            else:\n",
    "                                # Otherwise, match content regex\n",
    "                                matches = re.findall(field_info[\"Content_Identifier\"], file_text, re.IGNORECASE)\n",
    "                                if matches:\n",
    "                                    alerts.append((file_path, file, field_name, \"Sensitive\"))\n",
    "\n",
    "    # Display Results\n",
    "    df_alerts = pd.DataFrame(alerts, columns=[\"File Path\", \"Filename\", \"Detected Field\", \"Classification\"])\n",
    "    print(df_alerts)\n",
    "    return df_alerts\n",
    "\n",
    "# Run the Folder Scan\n",
    "folder_to_scan = \"/path/to/your/documents\"  # Change to your target folder\n",
    "scan_results = scan_folder_for_sensitive_data(folder_to_scan)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
