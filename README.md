
# **Creation of Intensive Care Unit (ICU) Dictionary and LLM Prototype**

Hi, 
In `icu_data_dict_granular.json` you have a dictionary for Intensive Care Unit (ICU) in construction, already with a few identifiers that were built following the  methodology outlined in the `README.md` file.

¬¥Identifier_Builder.ipynb¬¥ shows my reasoning to build each identifier, strictly following the methodology.

`generate_random_documents.ipynb` creates documents so I can apply the LLM classification on their contents.

The LLM classification is part of the `DLP_Product_Prototype.ipynb` which identifies sensitive data in documents and adds a watermark on them as a psychological deterrent,
and adds the sensitive label on the document's meta data.

## **Methodology Overview**
This document outlines the strategy employed for collecting and structuring ICU-specific data points, as well as the **general methodology used to develop the identifier dictionary**.

---

## **Specific Approach to ICU Data**

### **1Ô∏è‚É£ Consulting an ICU Expert for Real-World Validation**
- Recognizing that source documentation alone cannot always be trusted, I took the **additional step of consulting an experienced ICU surgeon** to identify the most **high-risk** and **relevant** patient data points in Brazil.  
- This ensured that the dataset had the **highest level of completeness and correctness** before implementing detection logic. Here are the most relevant datapoints to be considered:

# **DLP Classification**  

| **Category**                     | **Data Points (Brazilian_ Portuguese)**                                       | **DLP Sensitivity Level** | **Potential Risks**                                  |
|-----------------------------------|------------------------------------------------------|---------------------------|-----------------------------------------------------|
| **Patient Identifiers (PHI)**     | Nome, N¬∫ Atendimento, N¬∫ Prontu√°rio, Data Nascimento | üî¥ High (PII/PHI)         | Identity theft, unauthorized access               |
| **Hospitalization Data**          | DIH (Data da Interna√ß√£o Hospitalar), DUTI (Data da Admiss√£o na UTI), LEITO                                    | üü† Medium                 | Exposure of admission dates could violate privacy |
| **Insurance & Financial Data**    | Conv√™nio, Seguro de sa√∫de                                          | üî¥ High                   | Insurance fraud, financial abuse                  |
| **Clinical & Medical Data**       | Diagn√≥sticos, Hist√≥ria Cl√≠nica, Ex F√≠sico, Impress√£o Evolutiva | üî¥ High (Sensitive PHI) | Misuse of medical history, blackmail risks       |
| **Medication & Treatment**        | Prescri√ß√£o, Antibi√≥ticos, Drogas em BIC            | üî¥ High (PHI)             | Prescription data leaks (e.g., opioids, controlled substances) |
| **Vital Signs & Monitoring**      | Sinais Vitais, Par√¢metros Ventilat√≥rios            | üü† Medium                 | Exposure could lead to manipulation of health status data |
| **Medical Devices & Procedures**  | Dispositivos Invasivos                              | üü† Medium                 | Security risk if combined with patient identifiers |
| **Medical Actions & Notes**       | Condutas                                           | üü† Medium                 | Internal procedures could reveal treatment plans |
| **Laboratory Data**               | Labs                                               | üî¥ High (PHI)             | Lab results often contain highly sensitive health markers |
| **Dietary Information**           | Dieta                                              | üü° Low                    | Less critical but still part of patient records  |



### **2Ô∏è‚É£ Cross-Checking with Standardized Medical Taxonomies**
To **enhance accuracy and interoperability**, I systematically reviewed the ICU dictionary against international standards. This approach ensures **scalability** in case the dictionary needs to be adapted for **multilingual or cross-border use**:
- **LOINC** (*Logical Observation Identifiers Names and Codes*) ‚Üí Standardized system for lab results & observations.
- **ICD** (*International Classification of Diseases*) ‚Üí Universal classification of medical diagnoses.
- **CPT Codes** (*Current Procedural Terminology*) ‚Üí Standardized list of medical procedures & ICU treatments.
- **SNOMED-CT** (*Systematized Nomenclature of Medicine - Clinical Terms*) ‚Üí Comprehensive terminology for diagnostics & procedures.

### **3Ô∏è‚É£ Dual-Level Detection: Field-Based & Value-Based**
To improve **structured and unstructured detection**, the system operates at two levels:

- **Field Identifier** ‚Üí Detects whether a **certain tag/field** is present in the dataset.  
- **Value Identifier** ‚Üí Identifies **possible values** that the field can assume.

This ensures compatibility with both **structured formats** (e.g., JSON, XML, relational databases) and **unstructured text** (e.g., free-text clinical notes).  
üîπ The **Value Identifier** can be progressively expanded by integrating **taxonomy-based** detection.

---

## **Prototype for Data-at-Rest Protection**
To **apply** the ICU dictionary in a real-world setting, I developed a prototype that performs **data-at-rest scanning**.

### **1Ô∏è‚É£ Traversing the Database with DFS**
- The system recursively scans **all folders and files** (including subdirectories) using **Depth-First Search (DFS)** to efficiently locate **documents of interest**.
- It processes **PDF, DOCX, and CSV** files, extracting their contents for analysis.

### **2Ô∏è‚É£ Detecting & Marking Sensitive Data**
If **sensitive data** is identified, the system **immediately applies two protective measures**:

1. **Watermarking** ‚Üí Embeds a **"Sensitive" watermark** in documents, acting as a **psychological deterrent** to prevent accidental leaks or mishandling.  
2. **Metadata Tagging** ‚Üí Adds a "Sensitive" flag to document metadata for **enhanced tracking** (e.g., if the file is **copied, altered, uploaded, downloaded, or shared**).  

---

# **General Methodology**

## **Linguistics-First Approach**
Before implementing detection logic, the identifier must be **linguistically robust**. The methodology ensures that it accounts for **morphological structures, domain-specific terminology, and variations**.

### **1Ô∏è‚É£ Morphological Analysis**
üîπ **Word Stem** ‚Üí Identifies the **fixed root** of words, utilizing **etymological understanding** and **NLP lemmatization tools**.  
üîπ **Prefixes, Postfixes & Inflections** ‚Üí Examines how words **change endings** in different contexts (e.g., **declension, conjugation, gender, case variations**).  
üîπ **Domain-Specific Usage** ‚Üí Recognizes **ICU-specific jargon, abbreviations, and medical terminology**.  
üîπ **Synonyms & Equivalent Concepts** ‚Üí Accounts for **alternative terms** that may express **the same underlying meaning**.

### **2Ô∏è‚É£ Translation into Symbolic Language (Regex, NLP, Encoding)**
Once the linguistic patterns are understood, the next step is converting them into **structured identifiers**.

#### **Handling Variations & Anomalies**
üîπ **Typo & Variation Handling** ‚Üí Implements **Regex-based typo correction** and **fuzzy matching algorithms** (Levenshtein distance, cosine similarity, etc.).  
üîπ **Encoding Challenges** ‚Üí Accounts for **special character removal** (e.g., "a√ß√£o" ‚Üí "acao") to ensure **ASCII compatibility**.  
üîπ **Whitespace Sensitivity** ‚Üí Ensures detection is **robust against spacing inconsistencies** (e.g., "NomePaciente" vs. "Nome Paciente").  

#### **Balancing Generalization & Precision**
- The key principle: **"As general as possible, as specific as necessary."**  
- This prevents **overfitting** to ICU-specific language while maintaining **high precision**.

### **3Ô∏è‚É£ Iterative Refinement**
üîπ **Regex Prototyping & Debugging** ‚Üí Live-testing with **Regex101** to fine-tune pattern structure.  
üîπ **LLM-Augmented Review** ‚Üí Although **LLMs struggle with low-level character recognition**, they are valuable for **spotting inconsistencies** and **suggesting missing cases**.

---

# **4Ô∏è‚É£ Stress-Testing the Identifier**
The goal is to **expose the identifier‚Äôs limitations and strengths** through a **multi-faceted stress-testing approach**.

### **1Ô∏è‚É£ Positive Stress-Test (PST)**
üîπ **Goal:** Ensure the identifier is **general enough**.  
üîπ **Method:** Generate a **large, randomized dataset** with **valid names, terms, and patterns**. Test against the identifier and verify **successful matches**.

### **2Ô∏è‚É£ Negative Stress-Test (NST)**
üîπ **Goal:** Ensure the identifier is **specific enough**.  
üîπ **Method:** Generate a **dataset of false positives**‚Äîtexts that **should NOT match** the pattern. Run tests to **eliminate false detections**.

### **3Ô∏è‚É£ Moriarty Stress-Test (MST)**
üîπ **Goal:** Simulate **adversarial evasion attempts**.  
üîπ **Method:** Take a step back and ask:  

> *"If I wanted to bypass this detection, how would I do it?"*  

Actively **attempt to break the identifier**. This can involve:  
‚úÖ **Creative obfuscation techniques**  
‚úÖ **Pattern manipulation (spacing, special characters, typos)**  
‚úÖ **Unstructured or fragmented text formatting**  

The best improvements **often go beyond Regex alone**‚Äîleading to **enhanced hybrid detection strategies**.

### **4Ô∏è‚É£ Time Stress-Test (TST)**
üîπ **Goal:** Ensure the identifier remains valid over time.  
üîπ **Method:**
- Tag each identifier with a **time sensitivity level** (e.g., *"Stable", "Likely to Change", "Requires Review"*).
- Implement a **scheduled review process** to reassess identifiers flagged as **unstable or evolving**.
- Use **automated monitoring** to detect changes in medical taxonomies (ICD, LOINC, etc.).  

### **5Ô∏è‚É£ Regex Usage & Implementation**
Regex is a core component of structured pattern detection, but its application requires **deliberate selection of functions and syntax** depending on the context.

- **Understand the available methods**:
  - `findall()` ‚Üí Extracts **all** matches in a given text.
  - `search()` ‚Üí Finds the **first** match, useful for presence checks.
  - `match()` ‚Üí Checks **only** at the start of the string.
  - `fullmatch()` ‚Üí Ensures the **entire string** matches the pattern.
  - `compile()` ‚Üí Pre-compiles the regex for **optimized reuse**.

- **Cross-check regex behavior across different languages**:
  - Python, Go, and JavaScript each have slight **variations in regex handling**.
  - Some engines allow **lookbehind assertions**, while others don‚Äôt.
  - Always test for **edge cases** where regex might fail due to compilation quirks.

### **6Ô∏è‚É£ Preventive Alignment with Client's DLP Readiness**
Depending on how well **the organization enforces DLP policies**, there may be **pre-existing structures** that can **enhance detection accuracy**.

‚úÖ **Fixed Identifier Standards** ‚Üí If certain **IDs** (e.g., patient IDs, case numbers) follow a strict **numeric or alphanumeric structure**, regex rules can be optimized to enforce **expected formats only**.  
‚úÖ **Standard Document Titles & Tags** ‚Üí If policies **require sensitive documents** to be **explicitly labeled**, DLP detection can **leverage these fields** instead of relying solely on content analysis.  
‚úÖ **Proactive Policy Integration** ‚Üí Work with the **client‚Äôs compliance team** to **align detection with existing data governance policies** (e.g., ensuring system-generated reports include structured metadata).  

By aligning **preventive strategies** with **automated detection**, we can **reduce false positives** while **reinforcing security** at the source.

---

# **Next Steps & Future Considerations**
- **Expand Taxonomy Matching** ‚Üí Integrate with **ICD-10, LOINC, and SNOMED-CT databases** for automated cross-referencing.  
- **Enhance Contextual Classification** ‚Üí Fine-tune **LLM-assisted detection** to classify sensitive data **beyond simple keyword matching**.  
- **Optimize Computational Performance** ‚Üí Reduce **false positives & negatives** while maintaining **high efficiency** for large-scale data scanning.  

---

## **Final Thoughts**
This methodology **ensures a rigorous, linguistically-grounded approach** to ICU data classification. By **combining domain expertise, structured taxonomies, and hybrid detection techniques**, the project lays a **strong foundation for robust DLP solutions** in healthcare.

**Excited to refine this further based on feedback!**